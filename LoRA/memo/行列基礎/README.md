# LoRA を支える行列基礎知識

LoRA の低ランク分解を理解するには、線形代数の基本概念をコンパクトに押さえておくと便利です。ここでは実装で頻繁に出会うキーワードを、直感と式の双方から整理します。

## 1. 自由度（Degrees of Freedom）
- 行列が独立に取れるパラメータの数。\(m \times n\) 行列なら最大で \(mn\) 個だが、ランク \(r\) の制約を課すと自由度は \(r(m + n - r)\) まで落ちる。
- LoRA では \(\Delta W \approx BA\) とすることで自由度を \(r(d_{\text{in}} + d_{\text{out}})\) まで圧縮し、計算・記憶コストを削減する。

## 2. ベクトル空間と張る
- 列ベクトルが張る空間（列空間）は、その列の線形結合で表せるベクトルの集合。独立な列ベクトルの本数がランク。
- 行列の「情報の方向数」と捉えると LoRA の「本質的な変化方向だけ学習する」という発想に繋がる。

## 3. 対称行列と直交対角化
- \(A = A^\top\) なら対称。実対称行列は必ず直交行列 \(Q\) で対角化できる（\(A = Q \Lambda Q^\top\)）。
- \(W^\top W\) や \(W W^\top\) がこの形なので、固有値計算が安定。SVD の基礎となる。

## 4. 対称正定値行列（SPD）
- \(x^\top A x > 0\) を満たす対称行列。固有値はすべて正。
- \(W^\top W\) は SPD であり、その固有値の平方根が特異値になる。内積やノルムを定義する際にも頻出。

## 5. 固有値・固有ベクトル
- \(A v = \lambda v\) を満たす \((\lambda, v)\) が固有値・固有ベクトル。
- 固有方程式: \(\det(A - \lambda I) = 0\)。2×2 なら二次方程式で解け、SVD の手計算にも使える。
- LoRA では直接は出ないが、SVD の途中（\(W^\top W\) の固有値）で登場。

## 6. 特異値・特異ベクトル
- 任意の \(m \times n\) 行列 \(W\) は \(W = U \Sigma V^\top\) と分解できる。ここで
  - \(\Sigma = \operatorname{diag}(\sigma_1, \ldots, \sigma_{\text{rank}})\) が特異値
  - \(U, V\) は直交行列で、それぞれ左／右特異ベクトルを列に持つ
- 特異値の 2 乗が \(W^\top W\)、\(W W^\top\) の固有値に一致するため、固有値問題を解くことで SVD が求まる。
- LoRA の「どこまで低ランクで近似するか」は特異値の落ち方で判断する。

## 7. 固有方程式のステップ（2×2 例）
1. \(A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}\) とする。
2. \(\det(A - \lambda I) = (a-\lambda)(d-\lambda) - bc = 0\) を解く。
3. 得られた \(\lambda\) を使って \((A - \lambda I)v = 0\) を解き、固有ベクトルを求める。
4. ベクトルを正規化して単位長にする。

この流れを \(W^\top W\) に適用して \(\sigma_i = \sqrt{\lambda_i}\) を得るのが SVD の基本。

## 8. 直交行列
- \(Q^\top Q = I\) を満たす行列。列（行）が互いに直交し、長さ 1。
- 直交行列を掛けても長さや角度が保存されるため、SVD で「回転」と「スケーリング」を分離する際に使われる。

## 9. ノルムとエネルギー
- Frobenius ノルム: \(\|W\|_F = \sqrt{\sum_{i,j} w_{ij}^2} = \sqrt{\sum_i \sigma_i^2}\)。
- 低ランク近似が「どれだけ情報を保持しているか」を評価する指標として、特異値の 2 乗和（エネルギー）を用いる。

## 10. まとめ
- LoRA の低ランク補正は「固有値問題（SVD）で意味のある方向だけを残す」操作。
- 各キーワードは互いにリンクしており、特異値 → 固有値 → SPD → 直交行列 → 自由度の順で押さえると理解しやすい。
